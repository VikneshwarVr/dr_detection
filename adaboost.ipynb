{"cells":[{"cell_type":"markdown","metadata":{"id":"XQaHv4Ee1FWm"},"source":["# **Importing and Extracting the dataset**"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13397,"status":"ok","timestamp":1679937152976,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"EawZ8KmbTVuZ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.metrics import classification_report\n","from keras.applications import InceptionResNetV2, VGG19, Xception"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1679937152978,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"SSyyxTJ2U571"},"outputs":[],"source":["train_path = r'aptos_augmented_images_resized/train'\n","test_path = r'aptos_augmented_images_resized/test'"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1679937152980,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"Nz9FmezHVrOa","outputId":"dafea44a-9cab-4822-be3b-36b8fcdb3984"},"outputs":[{"ename":"NotFoundError","evalue":"Could not find directory aptos_augmented_images_resized/train","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marea\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m validationData \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(train_path,validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m'\u001b[39m,image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m),batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m,seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m testing_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(test_path,interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m'\u001b[39m,image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m),shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Asus\\OneDrive\\Desktop\\DR_detection_using_ensemble_learning\\env\\Lib\\site-packages\\keras\\src\\utils\\image_dataset.py:213\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Asus\\OneDrive\\Desktop\\DR_detection_using_ensemble_learning\\env\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:542\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    544\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[1;32mc:\\Users\\Asus\\OneDrive\\Desktop\\DR_detection_using_ensemble_learning\\env\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    778\u001b[0m ]\n","\u001b[1;31mNotFoundError\u001b[0m: Could not find directory aptos_augmented_images_resized/train"]}],"source":["training_data = tf.keras.utils.image_dataset_from_directory(train_path,validation_split=0.1,interpolation='area',image_size=(128,128),batch_size=8,subset='training',seed=42,color_mode='rgb')\n","validationData = tf.keras.utils.image_dataset_from_directory(train_path,validation_split=0.1,interpolation='area',image_size=(128,128),batch_size=8,subset='validation',seed=42,color_mode='rgb')\n","testing_data = tf.keras.utils.image_dataset_from_directory(test_path,interpolation='area',image_size=(128,128),shuffle=False,batch_size=16)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SJ5qjXn1zpOB"},"source":["# **Defining Models**\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10610,"status":"ok","timestamp":1679937163577,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"xByJ3T_K0cVB"},"outputs":[],"source":["inceptionResnet = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n","xception = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n","vgg = Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gtb6tVOUyR2i"},"source":["# **AdaBoost**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oCWcIW1jyXDx"},"source":["<h2>Compute Error, Alpha and weight</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679937163578,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"hDWVnaAif8Ll"},"outputs":[],"source":["# Compute error, alpha and weight\n","def compute_error(y, y_pred, w_i):\n","    '''\n","    Calculate the error rate of a weak classifier m. \n","    Arguments:\n","        y: actual target value\n","        y_pred: predicted value by weak classifier\n","        w_i: individual weights for each observation\n","\n","    '''\n","    return (sum(w_i * (np.not_equal(y, y_pred)).astype(int)))/sum(w_i)\n","\n","def compute_alpha(error):\n","    '''\n","    Calculate the weight of a weak classifier m in the majority vote of the final classifier.\n","    Arguments:\n","        error: error rate from weak classifier m\n","    '''\n","    return np.log((1 - error) / error)\n","\n","def update_weights(w_i, alpha, y, y_pred):\n","    ''' \n","    Update individual weights w_i after a boosting iteration.\n","    Arguments:\n","        w_i: individual weights for each observation\n","        y: actual target value\n","        y_pred: predicted value by weak classifier  \n","        alpha: weight of weak classifier used to estimate y_pred\n","    '''  \n","    return w_i * np.exp(alpha * (np.not_equal(y, y_pred)).astype(int))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2>Epoch vs Accuracy Graph</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679937163578,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"2Gp2M-x8bGqq"},"outputs":[],"source":["# Function to plot epoch vs accuracy graph\n","\n","def print_history(model_history):\n","\n","  # summarize history for accuracy\n","  plt.plot(model_history.history['accuracy'])\n","  plt.plot(model_history.history['val_accuracy'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'validation'], loc='upper left')\n","  plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2>Defining Adaboost Class</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679937163579,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"897ZfzDnhi6U"},"outputs":[],"source":["# Define AdaBoost class\n","class AdaBoost:\n","    \n","    def __init__(self):\n","        self.alphas = []\n","        self.G_M = []\n","        self.M = None\n","        self.training_errors = []\n","        self.prediction_errors = []\n","\n","    def fit(self, training_data, M = 3):\n","        '''\n","        Fit model.\n","        Arguments:\n","            X: independent variables - array-like matrix\n","            y: target variable - array-like vector\n","            M: number of boosting rounds. Default is 3 - integer\n","        '''\n","        \n","        # Clear before calling\n","        self.alphas = [] \n","        self.training_errors = []\n","        self.M = M\n","\n","        test_labels = []\n","        for i in range(0,5):\n","            for j in range(0,400):\n","                test_labels.append(i)\n","        y = np.array(test_labels,dtype='int8')\n","\n","\n","        # Iterate over M weak classifiers\n","        for m in range(0, M):\n","            \n","            # Set weights for current boosting iteration\n","            if m == 0:\n","                w_i = np.ones(len(y)) * 1 / len(y)  # At m = 0, weights are all the same and equal to 1 / N\n","            else:\n","                # (d) Update w_i\n","                w_i = update_weights(w_i, alpha_m, y, y_pred)\n","            \n","\n","            # (a) Fit weak classifier and predict labels\n","            if (m % 3) == 0:\n","                  new_model = inceptionResnet\n","            elif (m % 3) == 1:\n","                  new_model = xception\n","            else:\n","                  new_model = vgg\n","\n","            # Creating rescaling layer add adding dense layers at the end of pretrained model to match the no. of classes \n","            G_m = tf.keras.Sequential()\n","            G_m.add(tf.keras.layers.Rescaling(scale=1./255))\n","            G_m.add(new_model)\n","            G_m.add(tf.keras.layers.Flatten())\n","            G_m.add(tf.keras.layers.Dense(500, activation='relu'))\n","            G_m.add(tf.keras.layers.Dense(100, activation='relu'))\n","            G_m.add(tf.keras.layers.Dense(5, activation='softmax'))\n","              \n","            G_m.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'],run_eagerly=True)\n","                  \n","            model_history = G_m.fit(training_data)\n","            print_history(model_history)\n","            pred = G_m.predict(training_data)\n","            y_pred = []\n","            for _ in pred:\n","              y_pred.append(np.argmax(_))\n","\n","            y_pred = np.array(y_pred)\n","\n","            \n","            self.G_M.append(G_m) # Save to list of weak classifiers\n","\n","            # (b) Compute error\n","            error_m = compute_error(y, y_pred, w_i)\n","            self.training_errors.append(error_m)\n","\n","            # (c) Compute alpha\n","            alpha_m = compute_alpha(error_m)\n","            self.alphas.append(alpha_m)\n","\n","        assert len(self.G_M) == len(self.alphas)\n","\n","    \n","    def predict(self, X):\n","        '''\n","        Predict using fitted model. \n","        Arguments:\n","            X: independent variables - array-like\n","        '''\n","\n","        # Initialise dataframe with weak predictions for each observation\n","        weak_preds = pd.DataFrame(index = range(len(X)), columns = range(self.M)) \n","\n","        # Predict class label for each weak classifier, weighted by alpha_m\n","        for m in range(self.M):\n","            y_pred_m = self.G_M[m].predict(X) * self.alphas[m]\n","            weak_preds.iloc[:,m] = y_pred_m\n","\n","        # Calculate final predictions\n","        y_pred = (1 * np.sign(weak_preds.T.sum())).astype(int)\n","\n","        return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7NZM6mGOhmz8","outputId":"b2743d6f-6835-4d48-d7eb-b4e07a5d043e"},"outputs":[],"source":["ab = AdaBoost()\n","\n","# train_labels = np.array([])\n","# for images, labels in training_data:\n","#     train_labels = np.concatenate((train_labels,labels.numpy()),axis=0)\n","\n","# train_labels.astype(int)\n","\n","# len(train_data)\n","# # len(train_labels)\n","\n","ab.fit(training_data,M = 3)\n","\n","# Predict on test set\n","# y_pred = ab.predict(validationData)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
